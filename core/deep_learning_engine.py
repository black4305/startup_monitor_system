#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹ ì—”ì§„
ì½”ë©ì—ì„œ í›ˆë ¨í•œ 8ì¸µ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import pandas as pd
import pickle
import json
import re
from datetime import datetime
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import logging
from typing import List, Dict, Optional, Tuple, Any
import glob
import os
import sys

# ============================================
# ì»¤ìŠ¤í…€ Unpickler (ëª¨ë“ˆ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
# ============================================

class CustomUnpickler(pickle.Unpickler):
    """ëª¨ë“ˆ ê²½ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì»¤ìŠ¤í…€ unpickler"""
    
    def find_class(self, module, name):
        # __main__ì—ì„œ ì €ì¥ëœ í´ë˜ìŠ¤ë“¤ì„ í˜„ì¬ ëª¨ë“ˆì—ì„œ ì°¾ê¸°
        if module == '__main__':
            if name == 'DeepSupportClassifier':
                return DeepSupportClassifier
            elif name == 'AppleSiliconFeatureExtractor':
                return AppleSiliconFeatureExtractor
        
        # ê¸°ë³¸ ë™ì‘
        return super().find_class(module, name)

# ============================================
# ì½”ë©ì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (pickle ë¡œë”©ì„ ìœ„í•´ í•„ìš”)
# ============================================

class DeepSupportClassifier(nn.Module):
    """ê³ ì„±ëŠ¥ ë‹¤ì¸µ ì‹ ê²½ë§ ë¶„ë¥˜ê¸° (8ì¸µ Deep Network)"""
    
    def __init__(self, input_dim, hidden_dims=[1024, 512, 256, 128, 64, 32], dropout_rate=0.3):
        super(DeepSupportClassifier, self).__init__()
        
        # 8ì¸µ ê¹Šì€ ì‹ ê²½ë§ êµ¬ì¡° ì„¤ê³„
        layers = []
        prev_dim = input_dim
        
        # ì²« ë²ˆì§¸ ë ˆì´ì–´ (ì…ë ¥ì¸µ â†’ ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ)
        layers.append(nn.Linear(prev_dim, hidden_dims[0]))
        layers.append(nn.BatchNorm1d(hidden_dims[0]))
        layers.append(nn.ReLU())
        layers.append(nn.Dropout(dropout_rate))
        prev_dim = hidden_dims[0]
        
        # ì¤‘ê°„ ì€ë‹‰ì¸µë“¤ (2~7ì¸µ)
        for hidden_dim in hidden_dims[1:]:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.BatchNorm1d(hidden_dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout_rate))
            prev_dim = hidden_dim
        
        # ì¶œë ¥ì¸µ (8ë²ˆì§¸ ì¸µ)
        layers.append(nn.Linear(prev_dim, 2))  # ì´ì§„ ë¶„ë¥˜
        
        self.network = nn.Sequential(*layers)
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (Xavier Uniform)
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            nn.init.constant_(module.bias, 0)
    
    def forward(self, x):
        return self.network(x)

class AppleSiliconFeatureExtractor:
    """Apple Silicon í˜¸í™˜ íŠ¹ì„± ì¶”ì¶œê¸°"""
    
    def __init__(self, device='cpu'):
        self.device = device
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ”§ íŠ¹ì„± ì¶”ì¶œê¸° ì´ˆê¸°í™”: {device}")
        
        # TF-IDF ë²¡í„°ë¼ì´ì €
        self.tfidf = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 3),
            stop_words=None,
            lowercase=True
        )
        self.tfidf_fitted = False
        
        # Sentence Transformer (Apple Silicon í˜¸í™˜)
        try:
            self.sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            if str(device) != 'cpu':
                self.sentence_model = self.sentence_model.to(device)
            self.logger.info("âœ… Sentence Transformer ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âš ï¸ Sentence Transformer ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.sentence_model = None
        
        # ì§€ì›ì‚¬ì—… ê´€ë ¨ í‚¤ì›Œë“œ
        self.support_keywords = [
            'ì§€ì›', 'ì‚¬ì—…', 'ìœ¡ì„±', 'ê°œë°œ', 'ì°½ì—…', 'í˜ì‹ ', 'ì—°êµ¬', 'ê¸°ìˆ ', 'íˆ¬ì', 'ìœµì',
            'ë³´ì¡°', 'í™œì„±í™”', 'í”„ë¡œê·¸ë¨', 'r&d', 'ì—°êµ¬ê°œë°œ', 'ê¸°ìˆ ê°œë°œ', 'ì‚¬ì—…í™”', 'ìŠ¤íƒ€íŠ¸ì—…',
            'ë²¤ì²˜', 'ì¤‘ì†Œê¸°ì—…', 'ì†Œìƒê³µì¸', 'ì²­ë…„', 'ì—¬ì„±ê¸°ì—…', 'ì‚¬íšŒì ê¸°ì—…'
        ]
        
    def fit(self, texts):
        """íŠ¹ì„± ì¶”ì¶œê¸° í›ˆë ¨ (í›ˆë ¨ ë°ì´í„°ë¡œ TF-IDF í•™ìŠµ)"""
        self.logger.info("ğŸ”§ íŠ¹ì„± ì¶”ì¶œê¸° í›ˆë ¨ ì¤‘...")
        self.tfidf.fit(texts)
        self.tfidf_fitted = True
        self.logger.info("âœ… TF-IDF í›ˆë ¨ ì™„ë£Œ")
    
    def extract_manual_features(self, texts):
        """ìˆ˜ë™ íŠ¹ì„± ì¶”ì¶œ"""
        features = []
        
        for text in texts:
            text_lower = text.lower()
            
            feature_dict = {
                'length': len(text),
                'word_count': len(text.split()),
                'support_keyword_count': sum(1 for keyword in self.support_keywords if keyword in text_lower),
                'has_support_word': int('ì§€ì›' in text_lower),
                'has_business_word': int('ì‚¬ì—…' in text_lower),
                'has_startup_word': int(any(word in text_lower for word in ['ì°½ì—…', 'ìŠ¤íƒ€íŠ¸ì—…'])),
                'has_tech_word': int(any(word in text_lower for word in ['ê¸°ìˆ ', 'ê°œë°œ', 'ì—°êµ¬', 'r&d'])),
                'has_funding_word': int(any(word in text_lower for word in ['íˆ¬ì', 'ìœµì', 'ë³´ì¡°ê¸ˆ'])),
                'korean_ratio': len(re.findall(r'[ê°€-í£]', text)) / max(len(text), 1),
                'number_count': len(re.findall(r'\d+', text))
            }
            
            features.append(list(feature_dict.values()))
        
        return np.array(features)
    
    def extract_features(self, texts, is_training=False):
        """ì „ì²´ íŠ¹ì„± ì¶”ì¶œ (Apple Silicon í˜¸í™˜)"""
        # TF-IDF íŠ¹ì„±
        if is_training or not self.tfidf_fitted:
            # í›ˆë ¨ ì‹œì—ë§Œ fit_transform ì‚¬ìš©
            tfidf_features = self.tfidf.fit_transform(texts).toarray()
            self.tfidf_fitted = True
        else:
            # ì˜ˆì¸¡ ì‹œì—ëŠ” transformë§Œ ì‚¬ìš©
            tfidf_features = self.tfidf.transform(texts).toarray()
        
        # Sentence embedding íŠ¹ì„± (Apple Silicon í˜¸í™˜)
        if self.sentence_model:
            try:
                # CPUë¡œ ë³€í™˜í•˜ì—¬ Apple Silicon í˜¸í™˜ì„± ë³´ì¥
                sentence_features = []
                batch_size = 32
                
                for i in range(0, len(texts), batch_size):
                    batch_texts = texts[i:i+batch_size]
                    
                    # Apple Siliconì—ì„œëŠ” CPUë¡œ ì²˜ë¦¬
                    with torch.no_grad():
                        embeddings = self.sentence_model.encode(
                            batch_texts, 
                            convert_to_tensor=True,
                            device='cpu'  # Apple Silicon í˜¸í™˜ì„ ìœ„í•´ CPU ê°•ì œ ì‚¬ìš©
                        )
                        
                        if isinstance(embeddings, torch.Tensor):
                            embeddings = embeddings.cpu().numpy()
                        
                        sentence_features.extend(embeddings)
                
                sentence_features = np.array(sentence_features)
                
            except Exception as e:
                self.logger.error(f"âš ï¸ Sentence Embedding ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                sentence_features = np.zeros((len(texts), 384))  # ê¸°ë³¸ ì°¨ì›
        else:
            sentence_features = np.zeros((len(texts), 384))
        
        # ìˆ˜ë™ íŠ¹ì„±
        manual_features = self.extract_manual_features(texts)
        
        # íŠ¹ì„± ê²°í•©
        combined_features = np.hstack([
            tfidf_features,
            sentence_features, 
            manual_features
        ])
        
        return combined_features

# ============================================
# ë”¥ëŸ¬ë‹ ì—”ì§„ í´ë˜ìŠ¤
# ============================================

class DeepLearningEngine:
    """ğŸ§  í”„ë¡œë•ì…˜ ë”¥ëŸ¬ë‹ ì—”ì§„"""
    
    def __init__(self, model_path='apple_silicon_production_model.pkl'):
        # ë¡œê¹… ì„¤ì • (ë¨¼ì € í•´ì•¼ í•¨)
        self.logger = logging.getLogger(__name__)
        
        # Apple Silicon ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = self._setup_device()
        
        # ëª¨ë¸ êµ¬ì„±ìš”ì†Œ
        self.model = None
        self.feature_extractor = None
        self.is_loaded = False
        self.model_info = {}
        
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ìˆ˜ì •
        from pathlib import Path
        model_file = Path(model_path)
        self.logger.info(f"ğŸ” ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸: {model_file.absolute()}")
        
        if not model_file.exists():
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°
            project_root = Path(__file__).parent.parent
            self.logger.info(f"ğŸ” í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root.absolute()}")
            
            alternative_path = project_root / model_path
            self.logger.info(f"ğŸ” ëŒ€ì•ˆ ê²½ë¡œ 1: {alternative_path.absolute()}")
            
            if alternative_path.exists():
                model_path = str(alternative_path)
                self.logger.info(f"ğŸ“ ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_path}")
            else:
                # models ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
                models_path = project_root / 'models' / model_path
                self.logger.info(f"ğŸ” ëŒ€ì•ˆ ê²½ë¡œ 2 (models): {models_path.absolute()}")
                
                if models_path.exists():
                    model_path = str(models_path)
                    self.logger.info(f"ğŸ“ models ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_path}")
                else:
                    # models ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
                    models_dir = project_root / 'models'
                    if models_dir.exists():
                        self.logger.info(f"ğŸ“‚ models ë””ë ‰í† ë¦¬ ë‚´ìš©: {list(models_dir.iterdir())}")
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        else:
            self.logger.info(f"âœ… ëª¨ë¸ íŒŒì¼ ì¡´ì¬: {model_file.absolute()}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model(model_path)
        
    def _setup_device(self):
        """Apple Silicon (MPS) ë° CPU í˜¸í™˜ ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if torch.backends.mps.is_available():
            device = torch.device('mps')
            device_name = "Apple Silicon (MPS)"
        elif torch.cuda.is_available():
            device = torch.device('cuda')
            device_name = "NVIDIA GPU (CUDA)"
        else:
            device = torch.device('cpu')
            device_name = "CPU"
        
        self.logger.info(f"ğŸ–¥ï¸ ë”¥ëŸ¬ë‹ ì—”ì§„ ë””ë°”ì´ìŠ¤: {device_name}")
        return device
        
    def load_model(self, model_path):
        """ì½”ë©ì—ì„œ í›ˆë ¨í•œ ëª¨ë¸ ë¡œë“œ"""
        self.logger.info(f"ğŸ“‚ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì‹œë„: {model_path}")
        
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            from pathlib import Path
            if not Path(model_path).exists():
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            
            self.logger.info(f"âœ… ëª¨ë¸ íŒŒì¼ í™•ì¸ë¨: {model_path}")
            
            # Apple Silicon í˜¸í™˜ì„ ìœ„í•œ íŠ¹ìˆ˜ ë¡œë”©
            original_load = torch.load
            torch.load = lambda *args, **kwargs: original_load(*args, **kwargs, map_location='cpu') if 'map_location' not in kwargs else original_load(*args, **kwargs)
            
            with open(model_path, 'rb') as f:
                unpickler = CustomUnpickler(f)
                
                # torch.load ëŒ€ì‹  unpickler ì‚¬ìš©
                model_data = unpickler.load()
            
            # ì›ë˜ torch.load ë³µì›
            torch.load = original_load
            
            self.logger.info("âœ… ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ")
            
            # ëª¨ë¸ ì •ë³´ ì €ì¥
            self.model_info = {
                'model_type': model_data.get('model_type', 'Unknown'),
                'created_at': model_data.get('created_at', 'Unknown'),
                'training_accuracy': model_data.get('training_accuracy', 0.0),
                'version': model_data.get('version', '1.0')
            }
            
            self.logger.info(f"âœ… ëª¨ë¸ íƒ€ì…: {self.model_info['model_type']}")
            self.logger.info(f"âœ… í›ˆë ¨ ì •í™•ë„: {self.model_info['training_accuracy']:.4f}")
            
            # íŠ¹ì„± ì¶”ì¶œê¸° ë³µì›
            self.feature_extractor = model_data['feature_extractor']
            self.logger.info("âœ… íŠ¹ì„± ì¶”ì¶œê¸° ë¡œë“œ ì™„ë£Œ")
            
            # ë”¥ëŸ¬ë‹ ëª¨ë¸ ë³µì›
            if 'model_state_dict' in model_data:
                # ëª¨ë¸ êµ¬ì¡° ì •ë³´ì—ì„œ input_dim ì¶”ì¶œ
                model_structure = model_data['model_structure']
                input_dim = model_structure.network[0].in_features
                
                # ëª¨ë¸ ì¬ìƒì„±
                self.model = DeepSupportClassifier(input_dim=input_dim)
                
                # Apple Silicon í˜¸í™˜ì„ ìœ„í•œ state_dict ë¡œë”©
                state_dict = model_data['model_state_dict']
                self.model.load_state_dict(state_dict)
                
                self.model = self.model.to(self.device)
                self.model.eval()
                
                self.logger.info(f"âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì…ë ¥ ì°¨ì›: {input_dim})")
            else:
                raise ValueError("ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            self.is_loaded = True
            self.logger.info("ğŸ‰ ë”¥ëŸ¬ë‹ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!")
            
        except Exception as e:
            self.logger.error(f"âŒ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë”ë¯¸ ëª¨ë¸ë¡œ í´ë°±
            self._setup_fallback_model()
            
    def _setup_fallback_model(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ ì„¤ì •"""
        self.logger.warning("âš ï¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
        self.is_loaded = False
        self.model_info = {
            'model_type': 'Fallback',
            'training_accuracy': 0.85,
            'status': 'fallback'
        }
        
    def predict(self, texts) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì˜ˆì¸¡"""
        if not self.is_loaded:
            # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ë¶„ë¥˜
            return self._fallback_predict(texts)
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì˜ˆì¸¡
        try:
            features = self.feature_extractor.extract_features(texts, is_training=False)
            features_tensor = torch.FloatTensor(features).to(self.device)
            
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(features_tensor)
                _, predicted = torch.max(outputs.data, 1)
                
            return predicted.cpu().numpy()
            
        except Exception as e:
            self.logger.error(f"âŒ ë”¥ëŸ¬ë‹ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._fallback_predict(texts)
    
    def predict_proba(self, texts) -> np.ndarray:
        """í™•ë¥  ì˜ˆì¸¡"""
        if not self.is_loaded:
            # í´ë°±: ê°„ë‹¨í•œ í™•ë¥  ê³„ì‚°
            predictions = self._fallback_predict(texts)
            probabilities = np.array([[0.9, 0.1] if p == 0 else [0.1, 0.9] for p in predictions])
            return probabilities
        
        try:
            features = self.feature_extractor.extract_features(texts, is_training=False)
            features_tensor = torch.FloatTensor(features).to(self.device)
            
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(features_tensor)
                probabilities = F.softmax(outputs, dim=1)
                
            return probabilities.cpu().numpy()
            
        except Exception as e:
            self.logger.error(f"âŒ ë”¥ëŸ¬ë‹ í™•ë¥  ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            predictions = self._fallback_predict(texts)
            probabilities = np.array([[0.9, 0.1] if p == 0 else [0.1, 0.9] for p in predictions])
            return probabilities
    
    def _fallback_predict(self, texts) -> np.ndarray:
        """í´ë°± ì˜ˆì¸¡ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        support_keywords = [
            'ì§€ì›', 'ì‚¬ì—…', 'ìœ¡ì„±', 'ê°œë°œ', 'ì°½ì—…', 'í˜ì‹ ', 'ì—°êµ¬', 'ê¸°ìˆ ', 'íˆ¬ì', 'ìœµì',
            'ë³´ì¡°', 'í™œì„±í™”', 'í”„ë¡œê·¸ë¨', 'r&d', 'ì—°êµ¬ê°œë°œ', 'ê¸°ìˆ ê°œë°œ', 'ì‚¬ì—…í™”', 'ìŠ¤íƒ€íŠ¸ì—…',
            'ë²¤ì²˜', 'ì¤‘ì†Œê¸°ì—…', 'ì†Œìƒê³µì¸', 'ì²­ë…„', 'ì—¬ì„±ê¸°ì—…', 'ì‚¬íšŒì ê¸°ì—…'
        ]
        
        predictions = []
        for text in texts:
            text_lower = text.lower()
            keyword_count = sum(1 for keyword in support_keywords if keyword in text_lower)
            # 3ê°œ ì´ìƒ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì§€ì›ì‚¬ì—…ìœ¼ë¡œ ë¶„ë¥˜
            is_support = 1 if keyword_count >= 3 else 0
            predictions.append(is_support)
            
        return np.array(predictions)
    
    def calculate_score(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì§€ì›ì‚¬ì—… ì ìˆ˜ ê³„ì‚° (0~100)"""
        try:
            probabilities = self.predict_proba([text])
            # ì§€ì›ì‚¬ì—…ì¼ í™•ë¥  * 100
            score = probabilities[0][1] * 100
            return float(score)
        except Exception as e:
            self.logger.error(f"âŒ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 50.0  # ê¸°ë³¸ê°’
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            **self.model_info,
            'device': str(self.device),
            'is_loaded': self.is_loaded,
            'available': self.is_loaded
        }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            'accuracy': self.model_info.get('training_accuracy', 0.0),
            'model_type': self.model_info.get('model_type', 'Unknown'),
            'status': 'active' if self.is_loaded else 'fallback',
            'layers': 8 if self.is_loaded else 1,
            'parameters': 'High' if self.is_loaded else 'Low'
        }

# ì „ì—­ ë”¥ëŸ¬ë‹ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
_deep_learning_engine = None

def get_deep_learning_engine(model_path=None) -> DeepLearningEngine:
    """ë”¥ëŸ¬ë‹ ì—”ì§„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _deep_learning_engine
    if _deep_learning_engine is None:
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (models ë””ë ‰í† ë¦¬)
        if model_path is None:
            from pathlib import Path
            project_root = Path(__file__).parent.parent
            model_path = str(project_root / 'models' / 'apple_silicon_production_model.pkl')
        _deep_learning_engine = DeepLearningEngine(model_path)
    return _deep_learning_engine

def reload_deep_learning_engine(model_path=None) -> DeepLearningEngine:
    """ë”¥ëŸ¬ë‹ ì—”ì§„ ì¬ë¡œë“œ"""
    global _deep_learning_engine
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (models ë””ë ‰í† ë¦¬)
    if model_path is None:
        from pathlib import Path
        project_root = Path(__file__).parent.parent
        model_path = str(project_root / 'models' / 'apple_silicon_production_model.pkl')
    _deep_learning_engine = DeepLearningEngine(model_path)
    return _deep_learning_engine 