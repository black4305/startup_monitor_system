"""
í”¼ë“œë°± ì²˜ë¦¬ ëª¨ë“ˆ - ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° AI í•™ìŠµ (ê°•í™”í•™ìŠµ í†µí•©)
"""

import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime
import json
import asyncio
import threading
from pathlib import Path

logger = logging.getLogger(__name__)

class FeedbackHandler:
    """ì‚¬ìš©ì í”¼ë“œë°± ì²˜ë¦¬ ë° í•™ìŠµ ê´€ë¦¬ (ê°•í™”í•™ìŠµ í†µí•©)"""
    
    def __init__(self, db_manager):
        self.db_manager = db_manager
        self.feedback_patterns = {}
        self.deletion_patterns = {}
        
        # ê°•í™”í•™ìŠµ ì—°ë™
        self.rl_optimizer = None
        self.feedback_queue = []
        self.min_feedback_for_rl = 5  # 5ê°œ í”¼ë“œë°±ë§ˆë‹¤ ê°•í™”í•™ìŠµ ì‹¤í–‰
        
        # ê°•í™”í•™ìŠµ ëª¨ë“ˆ ë¡œë“œ ì‹œë„
        self._initialize_reinforcement_learning()
        
    def _initialize_reinforcement_learning(self):
        """ê°•í™”í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        try:
            from .reinforcement_learning_optimizer import ReinforcementLearningOptimizer
            
            # AI ì—”ì§„ ì°¸ì¡° (ë‚˜ì¤‘ì— ì„¤ì •)
            self.rl_optimizer = None
            logger.info("ğŸ¤– ê°•í™”í•™ìŠµ ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê°•í™”í•™ìŠµ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.rl_optimizer = None
    
    def set_ai_engine(self, ai_engine):
        """AI ì—”ì§„ ì°¸ì¡° ì„¤ì • (ê°•í™”í•™ìŠµìš©)"""
        try:
            if self.rl_optimizer is None:
                from .reinforcement_learning_optimizer import ReinforcementLearningOptimizer
                self.rl_optimizer = ReinforcementLearningOptimizer(ai_engine=ai_engine)
                logger.info("âœ… ê°•í™”í•™ìŠµ ìµœì í™”ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ AI ì—”ì§„ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def record_user_feedback(self, program_data: Dict, action: str, reason: str = "") -> bool:
        """ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë¡ ë° ì‹¤ì‹œê°„ í•™ìŠµ"""
        try:
            program_id = program_data.get('external_id', program_data.get('id', ''))
            
            # DBì— í”¼ë“œë°± ì €ì¥
            success = self.db_manager.insert_user_feedback(
                program_external_id=program_id,
                action=action,
                reason=reason,
                confidence=program_data.get('ai_score', 0) / 100.0
            )
            
            if success:
                # íŒ¨í„´ ì—…ë°ì´íŠ¸
                self.update_patterns_from_feedback(program_data, action, reason)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.update_feedback_stats(action, reason)
                
                # ê°•í™”í•™ìŠµ íì— ì¶”ê°€
                self._add_to_rl_queue(program_data, action, reason)
                
                # ì‚­ì œ ì•¡ì…˜ì¸ ê²½ìš° ìœ ì‚¬í•œ í”„ë¡œê·¸ë¨ ìë™ ì‚­ì œ (ë°±ê·¸ë¼ìš´ë“œ)
                if action == 'delete':
                    import threading
                    delete_thread = threading.Thread(
                        target=self.auto_delete_similar_programs,
                        args=(program_data, reason)
                    )
                    delete_thread.daemon = True
                    delete_thread.start()
                
                # ì¬í›ˆë ¨ í•„ìš”ì„± ì²´í¬
                self.check_retrain_needed()
                
                logger.info(f"âœ… í”¼ë“œë°± ê¸°ë¡: {action} - {program_data.get('title', '')[:50]}")
                return True
            else:
                logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def _add_to_rl_queue(self, program_data: Dict, action: str, reason: str):
        """ê°•í™”í•™ìŠµ íì— í”¼ë“œë°± ì¶”ê°€"""
        try:
            # í”¼ë“œë°± ë°ì´í„° êµ¬ì„±
            feedback_item = {
                'program_data': program_data,
                'action': action,
                'reason': reason,
                'timestamp': datetime.now().isoformat(),
                'title': program_data.get('title', ''),
                'content': program_data.get('content', ''),
                'ai_score': program_data.get('ai_score', 0)
            }
            
            self.feedback_queue.append(feedback_item)
            
            # ì¶©ë¶„í•œ í”¼ë“œë°±ì´ ìŒ“ì´ë©´ ê°•í™”í•™ìŠµ ì‹¤í–‰
            if len(self.feedback_queue) >= self.min_feedback_for_rl:
                self._trigger_reinforcement_learning()
                
            logger.info(f"ğŸ§  ê°•í™”í•™ìŠµ í ì¶”ê°€: {len(self.feedback_queue)}ê°œ ëŒ€ê¸° ì¤‘")
            
        except Exception as e:
            logger.error(f"âŒ ê°•í™”í•™ìŠµ í ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def _trigger_reinforcement_learning(self):
        """ê°•í™”í•™ìŠµ íŠ¸ë¦¬ê±° (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)"""
        if not self.rl_optimizer or len(self.feedback_queue) < self.min_feedback_for_rl:
            return
        
        def run_rl_optimization():
            try:
                logger.info(f"ğŸš€ ê°•í™”í•™ìŠµ ì‹œì‘: {len(self.feedback_queue)}ê°œ í”¼ë“œë°± ì²˜ë¦¬")
                
                # ì‹¤ì œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì‹¤í–‰
                result = self.rl_optimizer.retrain_deep_learning_model(self.feedback_queue)
                
                if result['status'] == 'success':
                    logger.info("âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì„±ê³µ!")
                    logger.info(f"   ì„±ëŠ¥ í–¥ìƒ: {result.get('improvement', 0):+.3f}")
                    logger.info(f"   í›ˆë ¨ëœ ì—í¬í¬: {result.get('epochs_trained', 0)}")
                    
                    # ì„±ê³µ ì‹œ í ë¹„ìš°ê¸°
                    self.feedback_queue.clear()
                    
                    # DBì— í•™ìŠµ ê²°ê³¼ ë¡œê¹…
                    self.db_manager.log_system_event(
                        level='INFO',
                        category='AI_LEARNING',
                        message='ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì™„ë£Œ',
                        details=result
                    )
                    
                else:
                    logger.warning(f"âš ï¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì‹¤íŒ¨: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
                    # ì‹¤íŒ¨í•œ ê²½ìš° ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™”ë¼ë„ ì‹œë„
                    if result['status'] != 'insufficient_data':
                        logger.info("ğŸ”„ ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™”ë¡œ í´ë°±...")
                        fallback_result = self.rl_optimizer.optimize_from_feedback(self.feedback_queue)
                        
                        if fallback_result.get('status') == 'success':
                            logger.info("âœ… ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™” ì„±ê³µ")
                            self.feedback_queue.clear()
                        
            except Exception as e:
                logger.error(f"âŒ ê°•í™”í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        thread = threading.Thread(target=run_rl_optimization, daemon=True)
        thread.start()
    
    def force_reinforcement_learning(self) -> Dict[str, Any]:
        """ê°•ì œ ê°•í™”í•™ìŠµ ì‹¤í–‰ (ìˆ˜ë™ íŠ¸ë¦¬ê±°)"""
        try:
            logger.info("ğŸ”§ ìˆ˜ë™ ê°•í™”í•™ìŠµ íŠ¸ë¦¬ê±°")
            
            if not self.rl_optimizer:
                return {
                    'status': 'no_optimizer',
                    'message': 'ê°•í™”í•™ìŠµ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.',
                    'timestamp': datetime.now().isoformat()
                }
            
            if len(self.feedback_queue) == 0:
                # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ìµœê·¼ í”¼ë“œë°±ì„ ê°€ì ¸ì™€ì„œ ì‹œë„
                recent_feedback = self.db_manager.get_recent_feedback(limit=10)
                if not recent_feedback:
                    return {
                        'status': 'no_feedback',
                        'message': 'í•™ìŠµí•  í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
                        'timestamp': datetime.now().isoformat()
                    }
                feedback_data = recent_feedback
            else:
                feedback_data = self.feedback_queue
            
            logger.info(f"ğŸ“š {len(feedback_data)}ê°œ í”¼ë“œë°±ìœ¼ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì‹œì‘...")
            
            # ì‹¤ì œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ ì‹¤í–‰
            result = self.rl_optimizer.retrain_deep_learning_model(feedback_data)
            
            if result['status'] == 'success':
                logger.info("ğŸ‰ ìˆ˜ë™ ë”¥ëŸ¬ë‹ ì¬í›ˆë ¨ ì„±ê³µ!")
                
                # ì„±ê³µ ì‹œ í ë¹„ìš°ê¸°
                self.feedback_queue.clear()
                
                # ìƒì„¸í•œ ê²°ê³¼ í¬í•¨
                return {
                    'status': 'success',
                    'message': 'ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!',
                    'result': result,
                    'improvement': result.get('improvement', 0),
                    'training_samples': result.get('training_samples', 0),
                    'epochs_trained': result.get('epochs_trained', 0),
                    'timestamp': datetime.now().isoformat()
                }
                
            elif result['status'] == 'insufficient_data':
                # ë°ì´í„° ë¶€ì¡± ì‹œ ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™”ë¼ë„ ì‹œë„
                logger.info("ğŸ”„ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œë„...")
                fallback_result = self.rl_optimizer.optimize_from_feedback(feedback_data)
                
                return {
                    'status': 'fallback_success',
                    'message': 'ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë©”íƒ€íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.',
                    'result': fallback_result,
                    'data_count': result.get('data_count', 0),
                    'timestamp': datetime.now().isoformat()
                }
                
            else:
                return {
                    'status': 'failed',
                    'message': result.get('message', 'ì¬í›ˆë ¨ ì‹¤íŒ¨'),
                    'error_details': result,
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"âŒ ìˆ˜ë™ ê°•í™”í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def get_rl_status(self) -> Dict[str, Any]:
        """ê°•í™”í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
        try:
            status = {
                'rl_available': self.rl_optimizer is not None,
                'feedback_queue_size': len(self.feedback_queue),
                'min_feedback_threshold': self.min_feedback_for_rl,
                'ready_for_rl': len(self.feedback_queue) >= self.min_feedback_for_rl
            }
            
            if self.rl_optimizer:
                status.update(self.rl_optimizer.get_rl_optimization_status())
            
            return status
            
        except Exception as e:
            logger.error(f"âŒ ê°•í™”í•™ìŠµ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'rl_available': False, 'error': str(e)}
    
    def update_patterns_from_feedback(self, program_data: Dict, action: str, reason: str):
        """í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        try:
            title = program_data.get('title', '')
            content = program_data.get('content', '')
            site_name = program_data.get('site_name', '')
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self.extract_keywords_from_text(f"{title} {content}")
            
            # íŒ¨í„´ë³„ ì—…ë°ì´íŠ¸
            pattern_updates = [
                ('keyword', action, keyword, reason) for keyword in keywords
            ]
            
            if site_name:
                pattern_updates.append(('site', action, site_name, reason))
            
            # ì‹¤ì œ DBì— íŒ¨í„´ ì €ì¥
            for pattern_type, category, pattern_key, reason in pattern_updates:
                self.db_manager.update_learning_pattern(
                    pattern_type=pattern_type,
                    category=category,
                    pattern_key=pattern_key,
                    reason=reason,
                    frequency_increment=1
                )
            
            logger.info(f"âœ… í•™ìŠµ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(pattern_updates)}ê°œ íŒ¨í„´ ì €ì¥")
            
        except Exception as e:
            logger.error(f"âŒ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def extract_keywords_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ê¸°ë²• ì‚¬ìš© ê°€ëŠ¥)
        keywords = []
        
        # ì§€ì›ì‚¬ì—… ê´€ë ¨ í‚¤ì›Œë“œë“¤
        important_keywords = [
            'ì°½ì—…', 'ì§€ì›', 'ì‚¬ì—…', 'ê¸°ì—…', 'íˆ¬ì', 'ìœµì', 'ë³´ì¡°ê¸ˆ',
            'R&D', 'ì—°êµ¬', 'ê°œë°œ', 'ê¸°ìˆ ', 'í˜ì‹ ', 'ë²¤ì²˜', 'ìŠ¤íƒ€íŠ¸ì—…',
            'ì¤‘ì†Œê¸°ì—…', 'ì†Œìƒê³µì¸', 'ìœ¡ì„±', 'í™œì„±í™”', 'ì´‰ì§„'
        ]
        
        text_lower = text.lower()
        for keyword in important_keywords:
            if keyword in text_lower:
                keywords.append(keyword)
        
        return keywords
    
    def update_feedback_stats(self, action: str, reason: str):
        """í”¼ë“œë°± í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            # í˜„ì¬ í†µê³„ ê°€ì ¸ì˜¤ê¸°
            current_stats = self.db_manager.get_user_feedback_stats()
            
            # í†µê³„ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ ë¡œê·¸ì— ê¸°ë¡
            self.db_manager.log_system_event(
                level='INFO',
                category='USER_ACTION',
                message=f'ì‚¬ìš©ì í”¼ë“œë°±: {action}',
                details={
                    'action': action,
                    'reason': reason,
                    'total_feedback': current_stats.get('total_feedback', 0) + 1,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ í”¼ë“œë°± í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def check_retrain_needed(self):
        """ì¬í›ˆë ¨ í•„ìš”ì„± ì²´í¬"""
        try:
            from .config import Config
            
            # ìµœê·¼ í”¼ë“œë°± ìˆ˜ í™•ì¸
            recent_feedback = self.db_manager.get_recent_feedback(limit=100)
            
            if len(recent_feedback) >= Config.MIN_FEEDBACK_FOR_RETRAIN:
                # ì¬í›ˆë ¨ ì•Œë¦¼ ìƒì„±
                self.create_retrain_notification(len(recent_feedback))
                
                logger.info(f"ğŸ”„ ì¬í›ˆë ¨ ê¶Œì¥: {len(recent_feedback)}ê°œ í”¼ë“œë°± ëˆ„ì ")
                
        except Exception as e:
            logger.error(f"âŒ ì¬í›ˆë ¨ ì²´í¬ ì‹¤íŒ¨: {e}")
    
    def create_retrain_notification(self, feedback_count: int):
        """ì¬í›ˆë ¨ ì•Œë¦¼ ìƒì„±"""
        try:
            self.db_manager.log_system_event(
                level='INFO',
                category='AI_LEARNING',
                message='AI ëª¨ë¸ ì¬í›ˆë ¨ ê¶Œì¥',
                details={
                    'feedback_count': feedback_count,
                    'recommendation': 'retrain_models',
                    'priority': 'high' if feedback_count > 10 else 'medium',
                    'timestamp': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ ì¬í›ˆë ¨ ì•Œë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def prepare_training_data(self) -> List[Tuple[str, int]]:
        """í”¼ë“œë°± ë°ì´í„°ë¥¼ í•™ìŠµìš© ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            # í”¼ë“œë°± ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            feedback_data = self.db_manager.get_recent_feedback(limit=1000)
            
            training_data = []
            for feedback in feedback_data:
                action = feedback.get('action', '')
                program_info = feedback.get('program_info', {})
                
                if isinstance(program_info, str):
                    try:
                        program_info = json.loads(program_info)
                    except:
                        continue
                
                title = program_info.get('title', '')
                content = program_info.get('content', '')
                text = f"{title} {content}".strip()
                
                if text and action in ['keep', 'delete']:
                    label = 1 if action == 'keep' else 0
                    training_data.append((text, label))
            
            logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(training_data)}ê°œ")
            return training_data
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return []
    
    def auto_delete_similar_programs(self, deleted_program: Dict, reason: str):
        """ì‚­ì œëœ í”„ë¡œê·¸ë¨ê³¼ ìœ ì‚¬í•œ í”„ë¡œê·¸ë¨ë“¤ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ ì‚­ì œ"""
        try:
            logger.info(f"ğŸ” ìœ ì‚¬ í”„ë¡œê·¸ë¨ ìë™ ì‚­ì œ ì‹œì‘: {deleted_program.get('title', '')[:50]}")
            
            # ìë™ ì‚­ì œ ìƒíƒœ ì´ˆê¸°í™”
            self.auto_delete_status = {
                'is_running': True,
                'total_programs': 0,
                'processed': 0,
                'deleted': 0,
                'current_program': '',
                'trigger_program': deleted_program.get('title', ''),
                'started_at': datetime.now().isoformat()
            }
            
            # ì‚­ì œëœ í”„ë¡œê·¸ë¨ì˜ íŠ¹ì§• ì¶”ì¶œ
            deleted_keywords = self.extract_keywords_from_text(
                f"{deleted_program.get('title', '')} {deleted_program.get('content', '')}"
            )
            deleted_site = deleted_program.get('site_name', '')
            
            # í™œì„±í™”ëœ ëª¨ë“  í”„ë¡œê·¸ë¨ ê°€ì ¸ì˜¤ê¸°
            active_programs = self.db_manager.get_all_programs(
                include_inactive=False,
                limit=1000
            )
            
            self.auto_delete_status['total_programs'] = len(active_programs)
            
            auto_deleted_count = 0
            auto_deleted_programs = []
            
            for i, program in enumerate(active_programs):
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                self.auto_delete_status['processed'] = i + 1
                self.auto_delete_status['current_program'] = program.get('title', '')[:50]
                
                # ì´ë¯¸ ì‚­ì œëœ í”„ë¡œê·¸ë¨ì€ ê±´ë„ˆë›°ê¸°
                if program.get('external_id') == deleted_program.get('external_id'):
                    continue
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                similarity_score = self.calculate_similarity(
                    program, deleted_program, deleted_keywords, deleted_site
                )
                
                # ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ ìë™ ì‚­ì œ (70% ì´ìƒ)
                if similarity_score >= 0.7:
                    logger.info(f"  â†’ ìœ ì‚¬ í”„ë¡œê·¸ë¨ ë°œê²¬ (ìœ ì‚¬ë„: {similarity_score:.1%}): {program.get('title', '')[:50]}")
                    
                    # 1. ìë™ ì‚­ì œ í”¼ë“œë°± ì €ì¥
                    feedback_success = self.db_manager.insert_user_feedback(
                        program_external_id=program.get('external_id'),
                        action='delete',
                        reason=f"ìë™ ì‚­ì œ - '{deleted_program.get('title', '')[:30]}'ì™€ ìœ ì‚¬ (ìœ ì‚¬ë„: {similarity_score:.1%})",
                        confidence=similarity_score
                    )
                    
                    # 2. í”„ë¡œê·¸ë¨ ë¹„í™œì„±í™”
                    if self.db_manager.deactivate_program(program.get('external_id')):
                        auto_deleted_count += 1
                        self.auto_delete_status['deleted'] = auto_deleted_count
                        auto_deleted_programs.append({
                            'title': program.get('title', ''),
                            'similarity': similarity_score,
                            'external_id': program.get('external_id')
                        })
                    
            # ìë™ ì‚­ì œ ì™„ë£Œ
            self.auto_delete_status['is_running'] = False
            self.auto_delete_status['completed_at'] = datetime.now().isoformat()
            
            if auto_deleted_count > 0:
                logger.info(f"âœ… ì´ {auto_deleted_count}ê°œ í”„ë¡œê·¸ë¨ ìë™ ì‚­ì œ ì™„ë£Œ")
                
                # ì‹œìŠ¤í…œ ë¡œê·¸ì— ê¸°ë¡
                self.db_manager.log_system_event(
                    level='INFO',
                    category='AUTO_DELETE',
                    message=f'ìœ ì‚¬ í”„ë¡œê·¸ë¨ ìë™ ì‚­ì œ',
                    details={
                        'trigger_program': deleted_program.get('title', ''),
                        'auto_deleted_count': auto_deleted_count,
                        'auto_deleted_programs': auto_deleted_programs[:10],  # ìµœëŒ€ 10ê°œë§Œ ë¡œê·¸ì— ê¸°ë¡
                        'timestamp': datetime.now().isoformat()
                    }
                )
            
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ í”„ë¡œê·¸ë¨ ìë™ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def calculate_similarity(self, program1: Dict, program2: Dict, keywords2: List[str], site2: str) -> float:
        """ë‘ í”„ë¡œê·¸ë¨ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0~1)"""
        try:
            # 1. í‚¤ì›Œë“œ ìœ ì‚¬ë„ (40%)
            keywords1 = self.extract_keywords_from_text(
                f"{program1.get('title', '')} {program1.get('content', '')}"
            )
            
            keyword_overlap = len(set(keywords1) & set(keywords2))
            keyword_total = len(set(keywords1) | set(keywords2))
            keyword_similarity = keyword_overlap / keyword_total if keyword_total > 0 else 0
            
            # 2. ì œëª© ìœ ì‚¬ë„ (30%)
            title1 = program1.get('title', '').lower()
            title2 = program2.get('title', '').lower()
            
            # ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ê°€ëŠ¥)
            title_words1 = set(title1.split())
            title_words2 = set(title2.split())
            title_overlap = len(title_words1 & title_words2)
            title_total = len(title_words1 | title_words2)
            title_similarity = title_overlap / title_total if title_total > 0 else 0
            
            # 3. ì‚¬ì´íŠ¸ ì¼ì¹˜ë„ (20%)
            site1 = program1.get('site_name', '')
            site_similarity = 1.0 if site1 == site2 else 0.0
            
            # 4. AI ì ìˆ˜ ìœ ì‚¬ë„ (10%)
            score1 = program1.get('ai_score', 50)
            score2 = program2.get('ai_score', 50)
            score_diff = abs(score1 - score2)
            score_similarity = 1.0 - (score_diff / 100.0)  # ì ìˆ˜ ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬
            
            # ì´ ìœ ì‚¬ë„ ê³„ì‚°
            total_similarity = (
                keyword_similarity * 0.4 +
                title_similarity * 0.3 +
                site_similarity * 0.2 +
                score_similarity * 0.1
            )
            
            return total_similarity
            
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def get_auto_delete_status(self) -> Dict[str, Any]:
        """ìë™ ì‚­ì œ ì§„í–‰ ìƒí™© ë°˜í™˜"""
        if hasattr(self, 'auto_delete_status'):
            return self.auto_delete_status
        else:
            return {'is_running': False}
    
    def get_learning_patterns(self) -> Dict[str, Any]:
        """í•™ìŠµëœ íŒ¨í„´ ì •ë³´ ë°˜í™˜"""
        try:
            patterns = self.db_manager.get_learning_patterns()
            
            # íŒ¨í„´ì„ ìœ í˜•ë³„ë¡œ ê·¸ë£¹í™”
            grouped_patterns = {
                'keywords': [],
                'sites': [],
                'actions': []
            }
            
            for pattern in patterns:
                pattern_type = pattern.get('pattern_type', '')
                if pattern_type == 'keyword':
                    grouped_patterns['keywords'].append(pattern)
                elif pattern_type == 'site':
                    grouped_patterns['sites'].append(pattern)
                else:
                    grouped_patterns['actions'].append(pattern)
            
            return grouped_patterns
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ íŒ¨í„´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'keywords': [], 'sites': [], 'actions': []}
    
    def get_feedback_summary(self) -> Dict[str, Any]:
        """í”¼ë“œë°± ìš”ì•½ ì •ë³´ (ê°•í™”í•™ìŠµ ì •ë³´ í¬í•¨)"""
        try:
            # í†µê³„ ì •ë³´
            stats = self.db_manager.get_user_feedback_stats()
            
            # ìµœê·¼ í”¼ë“œë°±
            recent_feedback = self.db_manager.get_recent_feedback(limit=10)
            
            # í•™ìŠµ íŒ¨í„´
            patterns = self.get_learning_patterns()
            
            # ê°•í™”í•™ìŠµ ìƒíƒœ
            rl_status = self.get_rl_status()
            
            return {
                'statistics': stats,
                'recent_feedback': recent_feedback,
                'learning_patterns': patterns,
                'reinforcement_learning': rl_status,
                'summary': {
                    'total_feedback': stats.get('total_feedback', 0),
                    'accuracy_trend': stats.get('accuracy_percentage', 0),
                    'pattern_count': sum(len(p) for p in patterns.values()),
                    'rl_queue_size': len(self.feedback_queue),
                    'last_updated': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ í”¼ë“œë°± ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'statistics': {},
                'recent_feedback': [],
                'learning_patterns': {'keywords': [], 'sites': [], 'actions': []},
                'reinforcement_learning': {'rl_available': False},
                'summary': {}
            } 