"""
AI ëª¨ë¸ ê´€ë¦¬ ëª¨ë“ˆ - ëª¨ë¸ ë¡œë”©, ì˜ˆì¸¡, ì ìˆ˜ ê³„ì‚°
"""

import logging
import pickle
import torch
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List, Optional, Any
from pathlib import Path
import os

from .config import Config

logger = logging.getLogger(__name__)

class AIModelManager:
    """AI ëª¨ë¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.device = Config.setup_device()
        self.bert_model = None
        self.bert_tokenizer = None
        self.sentence_model = None
        self.colab_models = {}
        self.deep_learning_model = None
        
        # ëª¨ë¸ ìƒíƒœ
        self.models_loaded = {
            'bert': False,
            'sentence': False,
            'colab': False,
            'deep_learning': False
        }
        
    def initialize_models(self):
        """ëª¨ë“  ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info("ğŸ¤– AI ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            # BERT ëª¨ë¸ ë¡œë“œ
            self.load_bert_model()
            
            # Sentence Transformer ë¡œë“œ
            self.load_sentence_model()
            
            # Colab í›ˆë ¨ ëª¨ë¸ ë¡œë“œ
            self.load_colab_models()
            
            # ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ
            self.load_deep_learning_model()
            
            logger.info("âœ… AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._setup_fallback_models()
    
    def load_bert_model(self):
        """BERT ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸ”¤ BERT ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.bert_tokenizer = AutoTokenizer.from_pretrained(Config.BERT_MODEL_NAME)
            self.bert_model = AutoModel.from_pretrained(Config.BERT_MODEL_NAME)
            self.bert_model.to(self.device)
            self.bert_model.eval()
            self.models_loaded['bert'] = True
            logger.info("âœ… BERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.models_loaded['bert'] = False
    
    def load_sentence_model(self):
        """Sentence Transformer ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸ”¤ Sentence Transformer ë¡œë”© ì¤‘...")
            self.sentence_model = SentenceTransformer(Config.SENTENCE_MODEL_NAME)
            if str(self.device) != 'cpu':
                self.sentence_model = self.sentence_model.to(self.device)
            self.models_loaded['sentence'] = True
            logger.info("âœ… Sentence Transformer ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ Sentence Transformer ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.models_loaded['sentence'] = False
    
    def load_colab_models(self):
        """Colabì—ì„œ í›ˆë ¨ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            logger.info("ğŸ“š Colab ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            model_paths = {
                'rf': Config.COLAB_RF_MODEL_PATH,
                'gb': Config.COLAB_GB_MODEL_PATH,
                'complete': Config.COLAB_COMPLETE_MODEL_PATH
            }
            
            loaded_count = 0
            for model_name, model_path in model_paths.items():
                if model_path.exists():
                    try:
                        with open(model_path, 'rb') as f:
                            self.colab_models[model_name] = pickle.load(f)
                        loaded_count += 1
                        logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            if loaded_count > 0:
                self.models_loaded['colab'] = True
                logger.info(f"âœ… Colab ëª¨ë¸ {loaded_count}ê°œ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("â„¹ï¸ Colab ë³„ë„ í›ˆë ¨ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì—†ìŠµë‹ˆë‹¤. (ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ ëŒ€ì²´)")
                self.models_loaded['colab'] = False
                
        except Exception as e:
            logger.error(f"âŒ Colab ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.models_loaded['colab'] = False
    
    def load_deep_learning_model(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ"""
        try:
            from .deep_learning_engine import get_deep_learning_engine
            
            logger.info("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.deep_learning_model = get_deep_learning_engine()
            
            if self.deep_learning_model and hasattr(self.deep_learning_model, 'is_loaded'):
                self.models_loaded['deep_learning'] = self.deep_learning_model.is_loaded
                logger.info("âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"âŒ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.models_loaded['deep_learning'] = False
    
    def _setup_fallback_models(self):
        """í´ë°± ëª¨ë¸ ì„¤ì •"""
        logger.info("ğŸ”„ í´ë°± ëª¨ë¸ ì„¤ì • ì¤‘...")
        
        class FallbackModel:
            def calculate_score(self, text):
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜
                keywords = ['ì§€ì›', 'ì‚¬ì—…', 'ì°½ì—…', 'ê¸°ì—…', 'íˆ¬ì', 'R&D']
                score = sum(10 for keyword in keywords if keyword in text)
                return min(score, 100)
            
            def get_model_info(self):
                return {'type': 'fallback', 'status': 'active'}
                
        self.fallback_model = FallbackModel()
    
    def calculate_bert_relevance(self, text: str) -> float:
        """BERT ëª¨ë¸ì„ ì‚¬ìš©í•œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if not self.models_loaded['bert']:
            return 0.0
            
        try:
            # í† í°í™”
            inputs = self.bert_tokenizer(
                text, 
                return_tensors='pt', 
                max_length=512, 
                truncation=True, 
                padding=True
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.bert_model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
                
                # ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
                score = torch.sigmoid(embeddings.sum()).item() * 100
                
            return min(max(score, 0), 100)
            
        except Exception as e:
            logger.warning(f"BERT ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def calculate_sentence_relevance(self, text: str) -> float:
        """Sentence Transformerë¥¼ ì‚¬ìš©í•œ ê´€ë ¨ì„± ì ìˆ˜"""
        if not self.models_loaded['sentence']:
            return 0.0
            
        try:
            # ì§€ì›ì‚¬ì—… ê´€ë ¨ ê¸°ì¤€ ë¬¸ì¥ë“¤
            reference_sentences = [
                "ì°½ì—… ì§€ì› ì‚¬ì—… ê³µê³ ",
                "ì¤‘ì†Œê¸°ì—… íˆ¬ì ìœ ì¹˜ í”„ë¡œê·¸ë¨",
                "ê¸°ìˆ ê°œë°œ R&D ì§€ì›",
                "ë²¤ì²˜ê¸°ì—… ìœ¡ì„± ì‚¬ì—…"
            ]
            
            # ì„ë² ë”© ê³„ì‚°
            text_embedding = self.sentence_model.encode([text])
            ref_embeddings = self.sentence_model.encode(reference_sentences)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            from sklearn.metrics.pairwise import cosine_similarity
            similarities = cosine_similarity(text_embedding, ref_embeddings)
            
            # ìµœëŒ€ ìœ ì‚¬ë„ë¥¼ ì ìˆ˜ë¡œ ì‚¬ìš©
            max_similarity = similarities.max()
            score = max_similarity * 100
            
            return min(max(score, 0), 100)
            
        except Exception as e:
            logger.warning(f"Sentence ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def calculate_colab_relevance(self, text: str) -> float:
        """Colab í›ˆë ¨ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì ìˆ˜ ê³„ì‚°"""
        if not self.models_loaded['colab']:
            return 0.0
            
        try:
            # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì‚¬ìš© (complete > gb > rf ìˆœ)
            model_priority = ['complete', 'gb', 'rf']
            
            for model_name in model_priority:
                if model_name in self.colab_models:
                    model = self.colab_models[model_name]
                    
                    if hasattr(model, 'predict_proba'):
                        # íŠ¹ì„± ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
                        features = self._extract_simple_features(text)
                        
                        # ì˜ˆì¸¡
                        proba = model.predict_proba([features])[0]
                        score = proba[1] * 100 if len(proba) > 1 else proba[0] * 100
                        
                        return min(max(score, 0), 100)
            
            return 0.0
            
        except Exception as e:
            logger.warning(f"Colab ëª¨ë¸ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def calculate_deep_learning_relevance(self, text: str) -> float:
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì ìˆ˜ ê³„ì‚°"""
        if not self.models_loaded['deep_learning']:
            return 0.0
            
        try:
            if self.deep_learning_model and hasattr(self.deep_learning_model, 'calculate_score'):
                score = self.deep_learning_model.calculate_score(text)
                return min(max(score, 0), 100)
            return 0.0
            
        except Exception as e:
            logger.warning(f"ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _extract_simple_features(self, text: str) -> List[float]:
        """ê°„ë‹¨í•œ íŠ¹ì„± ì¶”ì¶œ"""
        features = [
            len(text),
            len(text.split()),
            text.count('ì§€ì›'),
            text.count('ì‚¬ì—…'),
            text.count('ì°½ì—…'),
            text.count('ê¸°ì—…'),
            text.count('íˆ¬ì'),
            text.count('R&D'),
            text.count('ê°œë°œ'),
            text.count('ê¸°ìˆ ')
        ]
        return features
    
    def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'models_loaded': self.models_loaded,
            'device': str(self.device),
            'device_name': Config.DEVICE_NAME,
            'colab_models_count': len(self.colab_models),
            'total_models': sum(self.models_loaded.values())
        }
    
    def predict(self, text: str) -> float:
        """í†µí•© ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚°"""
        scores = []
        weights = []
        
        # BERT ì ìˆ˜
        if self.models_loaded['bert']:
            bert_score = self.calculate_bert_relevance(text)
            scores.append(bert_score)
            weights.append(Config.BERT_WEIGHT)
        
        # Sentence ì ìˆ˜
        if self.models_loaded['sentence']:
            sentence_score = self.calculate_sentence_relevance(text)
            scores.append(sentence_score)
            weights.append(0.3)
        
        # Colab ëª¨ë¸ ì ìˆ˜
        if self.models_loaded['colab']:
            colab_score = self.calculate_colab_relevance(text)
            scores.append(colab_score)
            weights.append(Config.COLAB_MODEL_WEIGHT)
        
        # ë”¥ëŸ¬ë‹ ì ìˆ˜
        if self.models_loaded['deep_learning']:
            dl_score = self.calculate_deep_learning_relevance(text)
            scores.append(dl_score)
            weights.append(0.5)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        if scores:
            weighted_score = sum(s * w for s, w in zip(scores, weights)) / sum(weights)
            return min(max(weighted_score, 0), 100)
        
        # í´ë°± ëª¨ë¸ ì‚¬ìš©
        if hasattr(self, 'fallback_model'):
            return self.fallback_model.calculate_score(text)
        
        return 0.0 